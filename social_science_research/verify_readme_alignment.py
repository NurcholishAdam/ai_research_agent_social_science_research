# -*- coding: utf-8 -*-
"""
README.md Alignment Verification
Ensures all components mentioned in README.md are implemented and functional
"""

import sys
import os
import importlib.util

def verify_component_exists(module_path: str, component_name: str) -> bool:
    """Verify a component exists and can be imported"""
    try:
        spec = importlib.util.spec_from_file_location(component_name, module_path)
        if spec is None:
            return False
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return True
    except Exception as e:
        print(f"‚ùå Error importing {component_name}: {e}")
        return False

def count_lines_in_file(file_path: str) -> int:
    """Count lines in a file"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return len(f.readlines())
    except Exception:
        return 0

def verify_readme_alignment():
    """Verify all README.md promises are fulfilled"""
    
    print("üîç Verifying README.md Alignment with Implementation")
    print("=" * 60)
    
    # Component verification
    components = {
        "Core Framework": "core/social_science_framework.py",
        "Survey Design": "data_collection/survey_design.py", 
        "Statistical Analysis": "analysis/statistical_analysis.py",
        "Mixed Methods Complete": "methodologies/mixed_methods_complete.py",
        "Mixed Methods Integration": "methodologies/mixed_methods_integration.py",
        "AI Integration": "ai_integration/enhanced_social_science_ai.py",
        "Demo System": "demo_complete_social_science_project.py",
        "Integration Tests": "test_complete_integration.py"
    }
    
    total_lines = 0
    all_components_exist = True
    
    print("\nüìÅ Component Verification:")
    for name, path in components.items():
        full_path = os.path.join(os.path.dirname(__file__), path)
        exists = os.path.exists(full_path)
        lines = count_lines_in_file(full_path) if exists else 0
        total_lines += lines
        
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {name}: {lines} lines")
        
        if not exists:
            all_components_exist = False
    
    print(f"\nüìä Total Lines of Code: {total_lines}")
    
    # Feature verification
    print("\nüéØ Feature Verification:")
    
    features_promised = [
        "Multi-Paradigm Integration",
        "Cross-Cultural Validation", 
        "Mixed-Methods Analysis",
        "RLHF Quality Assessment",
        "Semantic Knowledge Integration",
        "Cultural Context Engineering",
        "Graph-Based Research Reasoning",
        "Automated Survey Design",
        "Advanced Statistical Analysis",
        "Mixed Methods Automation"
    ]
    
    # Check if key features are implemented
    base_dir = os.path.dirname(__file__)
    
    def read_file_safe(path):
        try:
            full_path = os.path.join(base_dir, path)
            with open(full_path, 'r', encoding='utf-8') as f:
                return f.read()
        except:
            return ""
    
    feature_implementations = {
        "Multi-Paradigm Integration": "ResearchParadigm" in read_file_safe("core/social_science_framework.py"),
        "Cross-Cultural Validation": "cross_cultural_analysis" in read_file_safe("core/social_science_framework.py"),
        "Mixed-Methods Analysis": os.path.exists(os.path.join(base_dir, "methodologies/mixed_methods_complete.py")),
        "RLHF Quality Assessment": "_apply_rlhf_feedback" in read_file_safe("ai_integration/enhanced_social_science_ai.py"),
        "Semantic Knowledge Integration": "_apply_semantic_graph_processing" in read_file_safe("ai_integration/enhanced_social_science_ai.py"),
        "Cultural Context Engineering": "_apply_contextual_engineering" in read_file_safe("ai_integration/enhanced_social_science_ai.py"),
        "Graph-Based Research Reasoning": "_apply_limit_graph_analysis" in read_file_safe("ai_integration/enhanced_social_science_ai.py"),
        "Automated Survey Design": "design_social_identity_scale" in read_file_safe("data_collection/survey_design.py"),
        "Advanced Statistical Analysis": "AdvancedStatisticalAnalyzer" in read_file_safe("analysis/statistical_analysis.py"),
        "Mixed Methods Automation": "integrate_explanatory_sequential" in read_file_safe("methodologies/mixed_methods_complete.py")
    }
    
    features_implemented = 0
    for feature, implemented in feature_implementations.items():
        status = "‚úÖ" if implemented else "‚ùå"
        print(f"{status} {feature}")
        if implemented:
            features_implemented += 1
    
    # AI Architecture verification
    print("\nü§ñ AI Architecture Verification:")
    ai_file_content = read_file_safe("ai_integration/enhanced_social_science_ai.py")
    
    ai_architectures = {
        "RLHF": "_apply_rlhf_feedback" in ai_file_content,
        "Semantic Graph": "_apply_semantic_graph_processing" in ai_file_content,
        "Contextual Engineering": "_apply_contextual_engineering" in ai_file_content,
        "LIMIT-Graph": "_apply_limit_graph_analysis" in ai_file_content
    }
    
    ai_implemented = 0
    for arch, implemented in ai_architectures.items():
        status = "‚úÖ" if implemented else "‚ùå"
        print(f"{status} {arch} Integration")
        if implemented:
            ai_implemented += 1
    
    # Statistical Methods verification
    print("\nüìà Statistical Methods Verification:")
    stats_file_content = read_file_safe("analysis/statistical_analysis.py")
    
    statistical_methods = [
        "descriptive_analysis", "correlation_analysis", "t_test_analysis",
        "anova_analysis", "regression_analysis", "factor_analysis",
        "cluster_analysis", "network_analysis"
    ]
    
    stats_implemented = 0
    for method in statistical_methods:
        implemented = method in stats_file_content
        status = "‚úÖ" if implemented else "‚ùå"
        print(f"{status} {method.replace('_', ' ').title()}")
        if implemented:
            stats_implemented += 1
    
    # Final assessment
    print("\n" + "=" * 60)
    print("üìã FINAL ASSESSMENT:")
    
    # Fix component count
    components_exist = 0
    for path in components.values():
        full_path = os.path.join(os.path.dirname(__file__), path)
        if os.path.exists(full_path):
            components_exist += 1
    
    print(f"‚úÖ Components: {components_exist}/{len(components)}")
    print(f"‚úÖ Features: {features_implemented}/{len(features_promised)}")
    print(f"‚úÖ AI Architectures: {ai_implemented}/4")
    print(f"‚úÖ Statistical Methods: {stats_implemented}/{len(statistical_methods)}")
    print(f"‚úÖ Total Lines: {total_lines:,}")
    
    # Overall score
    component_score = components_exist / len(components)
    feature_score = features_implemented / len(features_promised)
    ai_score = ai_implemented / 4
    stats_score = stats_implemented / len(statistical_methods)
    
    overall_score = (component_score + feature_score + ai_score + stats_score) / 4
    
    print(f"\nüéØ Overall Alignment Score: {overall_score:.1%}")
    
    if overall_score >= 0.9:
        print("üéâ EXCELLENT: README.md fully aligned with implementation!")
    elif overall_score >= 0.8:
        print("‚úÖ GOOD: README.md mostly aligned with implementation")
    elif overall_score >= 0.7:
        print("‚ö†Ô∏è  FAIR: Some alignment issues detected")
    else:
        print("‚ùå POOR: Significant alignment issues")
    
    return overall_score >= 0.9

if __name__ == "__main__":
    success = verify_readme_alignment()
    
    if success:
        print("\nüèÜ README.md VERIFICATION PASSED!")
        print("All promised features are implemented and functional.")
    else:
        print("\n‚ö†Ô∏è  README.md verification found some issues.")
        print("Please review the output above for details.")